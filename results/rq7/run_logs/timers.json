{
    "name": "root",
    "gauges": {
        "CRB15000.Policy.Entropy.mean": {
            "value": -0.977200448513031,
            "min": -0.9821059107780457,
            "max": -0.9597366452217102,
            "count": 31
        },
        "CRB15000.Policy.Entropy.sum": {
            "value": -40167.82421875,
            "min": -40403.77734375,
            "max": -39260.2265625,
            "count": 31
        },
        "CRB15000.Environment.EpisodeLength.mean": {
            "value": 99.0,
            "min": 86.98712446351931,
            "max": 99.0,
            "count": 31
        },
        "CRB15000.Environment.EpisodeLength.sum": {
            "value": 40590.0,
            "min": 40491.0,
            "max": 40598.0,
            "count": 31
        },
        "CRB15000.Step.mean": {
            "value": 1269749.0,
            "min": 40902.0,
            "max": 1269749.0,
            "count": 31
        },
        "CRB15000.Step.sum": {
            "value": 1269749.0,
            "min": 40902.0,
            "max": 1269749.0,
            "count": 31
        },
        "CRB15000.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.11137165129184723,
            "min": -0.11137165129184723,
            "max": 1.115370750427246,
            "count": 31
        },
        "CRB15000.Policy.ExtrinsicValueEstimate.sum": {
            "value": -45.662376403808594,
            "min": -45.662376403808594,
            "max": 457.302001953125,
            "count": 31
        },
        "CRB15000.Environment.CumulativeReward.mean": {
            "value": -0.26390781944117897,
            "min": -0.28600296789451024,
            "max": -0.13215616361177976,
            "count": 31
        },
        "CRB15000.Environment.CumulativeReward.sum": {
            "value": -108.20220597088337,
            "min": -118.11922574043274,
            "max": -61.45261607947759,
            "count": 31
        },
        "CRB15000.Policy.ExtrinsicReward.mean": {
            "value": -0.26390781944117897,
            "min": -0.28600296789451024,
            "max": -0.13215616361177976,
            "count": 31
        },
        "CRB15000.Policy.ExtrinsicReward.sum": {
            "value": -108.20220597088337,
            "min": -118.11922574043274,
            "max": -61.45261607947759,
            "count": 31
        },
        "CRB15000.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 31
        },
        "CRB15000.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 31
        },
        "CRB15000.Losses.PolicyLoss.mean": {
            "value": 0.01211695283923291,
            "min": 0.009597262878924085,
            "max": 0.0512518380623078,
            "count": 30
        },
        "CRB15000.Losses.PolicyLoss.sum": {
            "value": 0.01211695283923291,
            "min": 0.009597262878924085,
            "max": 0.0512518380623078,
            "count": 30
        },
        "CRB15000.Losses.ValueLoss.mean": {
            "value": 0.0005508982800165541,
            "min": 0.00022662343671981945,
            "max": 0.014775364263914525,
            "count": 30
        },
        "CRB15000.Losses.ValueLoss.sum": {
            "value": 0.0005508982800165541,
            "min": 0.00022662343671981945,
            "max": 0.014775364263914525,
            "count": 30
        },
        "CRB15000.Policy.LearningRate.mean": {
            "value": 0.00022619108460298002,
            "min": 0.00022619108460298002,
            "max": 0.00029753988082004,
            "count": 30
        },
        "CRB15000.Policy.LearningRate.sum": {
            "value": 0.00022619108460298002,
            "min": 0.00022619108460298002,
            "max": 0.00029753988082004,
            "count": 30
        },
        "CRB15000.Policy.Epsilon.mean": {
            "value": 0.17539702000000004,
            "min": 0.17539702000000004,
            "max": 0.19917996,
            "count": 30
        },
        "CRB15000.Policy.Epsilon.sum": {
            "value": 0.17539702000000004,
            "min": 0.17539702000000004,
            "max": 0.19917996,
            "count": 30
        },
        "CRB15000.Policy.Beta.mean": {
            "value": 0.003772311298000001,
            "min": 0.003772311298000001,
            "max": 0.004959080004,
            "count": 30
        },
        "CRB15000.Policy.Beta.sum": {
            "value": 0.003772311298000001,
            "min": 0.003772311298000001,
            "max": 0.004959080004,
            "count": 30
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1719409211",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\18125\\anaconda3\\envs\\mlagents\\Scripts\\mlagents-learn ./config/HighBatch.yaml --run-id rq7 --env=./Builds/rq7/ABB-RL --num-envs=8 --initialize-from rq4 --force",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.3.0+cpu",
        "numpy_version": "1.22.4",
        "end_time_seconds": "1719430381"
    },
    "total": 21169.50582650001,
    "count": 1,
    "self": 4.833072999957949,
    "children": {
        "run_training.setup": {
            "total": 0.35075480001978576,
            "count": 1,
            "self": 0.35075480001978576
        },
        "TrainerController.start_learning": {
            "total": 21164.321998700034,
            "count": 1,
            "self": 20.446950203040615,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.3001863999525085,
                    "count": 1,
                    "self": 7.3001863999525085
                },
                "TrainerController.advance": {
                    "total": 21136.542888497002,
                    "count": 1310135,
                    "self": 19.480355853098445,
                    "children": {
                        "env_step": {
                            "total": 20319.7499017691,
                            "count": 1310135,
                            "self": 19226.826309799217,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1079.0862860160414,
                                    "count": 1318325,
                                    "self": 58.98674611561,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1020.0995399004314,
                                            "count": 1305230,
                                            "self": 1020.0995399004314
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 13.837305953842588,
                                    "count": 1310134,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 169227.75874611584,
                                            "count": 1318317,
                                            "is_parallel": true,
                                            "self": 7814.046918711509,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.001241800026036799,
                                                    "count": 8,
                                                    "is_parallel": true,
                                                    "self": 0.00048530043568462133,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0007564995903521776,
                                                            "count": 16,
                                                            "is_parallel": true,
                                                            "self": 0.0007564995903521776
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 161413.7105856043,
                                                    "count": 1318317,
                                                    "is_parallel": true,
                                                    "self": 92.0239496655995,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 70.21223586099222,
                                                            "count": 1318317,
                                                            "is_parallel": true,
                                                            "self": 70.21223586099222
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 161031.39476420474,
                                                            "count": 1318317,
                                                            "is_parallel": true,
                                                            "self": 161031.39476420474
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 220.07963587297127,
                                                            "count": 1318317,
                                                            "is_parallel": true,
                                                            "self": 109.05842733115423,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 111.02120854181703,
                                                                    "count": 2636634,
                                                                    "is_parallel": true,
                                                                    "self": 111.02120854181703
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 797.3126308748033,
                            "count": 1310134,
                            "self": 22.002518105553463,
                            "children": {
                                "process_trajectory": {
                                    "total": 85.89499666937627,
                                    "count": 1310134,
                                    "self": 85.34019766934216,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.5547990000341088,
                                            "count": 13,
                                            "self": 0.5547990000341088
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 689.4151160998736,
                                    "count": 31,
                                    "self": 485.47425559919793,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 203.94086050067563,
                                            "count": 2480,
                                            "self": 203.94086050067563
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.100008375942707e-06,
                    "count": 1,
                    "self": 1.100008375942707e-06
                },
                "TrainerController._save_models": {
                    "total": 0.031972500029951334,
                    "count": 1,
                    "self": 0.00512039999011904,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.026852100039832294,
                            "count": 1,
                            "self": 0.026852100039832294
                        }
                    }
                }
            }
        }
    }
}