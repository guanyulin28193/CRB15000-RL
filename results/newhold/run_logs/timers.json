{
    "name": "root",
    "gauges": {
        "CRB15000.Policy.Entropy.mean": {
            "value": -1.076305866241455,
            "min": -1.076305866241455,
            "max": -1.0441445112228394,
            "count": 33
        },
        "CRB15000.Policy.Entropy.sum": {
            "value": -44165.13671875,
            "min": -44165.13671875,
            "max": -26297.822265625,
            "count": 33
        },
        "CRB15000.Environment.EpisodeLength.mean": {
            "value": 48.96219512195122,
            "min": 48.86845310596833,
            "max": 49.0,
            "count": 33
        },
        "CRB15000.Environment.EpisodeLength.sum": {
            "value": 40149.0,
            "min": 24593.0,
            "max": 40180.0,
            "count": 33
        },
        "CRB15000.Step.mean": {
            "value": 9052141.0,
            "min": 7741402.0,
            "max": 9052141.0,
            "count": 33
        },
        "CRB15000.Step.sum": {
            "value": 9052141.0,
            "min": 7741402.0,
            "max": 9052141.0,
            "count": 33
        },
        "CRB15000.Policy.ExtrinsicValueEstimate.mean": {
            "value": 4.996057033538818,
            "min": 4.839962482452393,
            "max": 4.996057033538818,
            "count": 33
        },
        "CRB15000.Policy.ExtrinsicValueEstimate.sum": {
            "value": 4096.7666015625,
            "min": 2429.732666015625,
            "max": 4096.7666015625,
            "count": 33
        },
        "CRB15000.Environment.CumulativeReward.mean": {
            "value": 1.5584437990606559,
            "min": 1.4873480168920827,
            "max": 1.6157599840131476,
            "count": 33
        },
        "CRB15000.Environment.CumulativeReward.sum": {
            "value": 1277.9239152297378,
            "min": 786.9064595196396,
            "max": 1324.923186890781,
            "count": 33
        },
        "CRB15000.Policy.ExtrinsicReward.mean": {
            "value": 1.5584437990606559,
            "min": 1.4873480168920827,
            "max": 1.6157599840131476,
            "count": 33
        },
        "CRB15000.Policy.ExtrinsicReward.sum": {
            "value": 1277.9239152297378,
            "min": 786.9064595196396,
            "max": 1324.923186890781,
            "count": 33
        },
        "CRB15000.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 33
        },
        "CRB15000.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 33
        },
        "CRB15000.Losses.PolicyLoss.mean": {
            "value": 0.01024839483834512,
            "min": 0.009435111710899946,
            "max": 0.013679381262227253,
            "count": 32
        },
        "CRB15000.Losses.PolicyLoss.sum": {
            "value": 0.01024839483834512,
            "min": 0.009435111710899946,
            "max": 0.013679381262227253,
            "count": 32
        },
        "CRB15000.Losses.ValueLoss.mean": {
            "value": 0.041839545220136644,
            "min": 0.026380648114718498,
            "max": 0.05797172700986266,
            "count": 32
        },
        "CRB15000.Losses.ValueLoss.sum": {
            "value": 0.041839545220136644,
            "min": 0.026380648114718498,
            "max": 0.05797172700986266,
            "count": 32
        },
        "CRB15000.Policy.LearningRate.mean": {
            "value": 2.9164860278410006e-05,
            "min": 2.9164860278410006e-05,
            "max": 6.728044757321e-05,
            "count": 32
        },
        "CRB15000.Policy.LearningRate.sum": {
            "value": 2.9164860278410006e-05,
            "min": 2.9164860278410006e-05,
            "max": 6.728044757321e-05,
            "count": 32
        },
        "CRB15000.Policy.Epsilon.mean": {
            "value": 0.10972159000000001,
            "min": 0.10972159000000001,
            "max": 0.12242679000000001,
            "count": 32
        },
        "CRB15000.Policy.Epsilon.sum": {
            "value": 0.10972159000000001,
            "min": 0.10972159000000001,
            "max": 0.12242679000000001,
            "count": 32
        },
        "CRB15000.Policy.Beta.mean": {
            "value": 0.0004951073410000003,
            "min": 0.0004951073410000003,
            "max": 0.001129096821,
            "count": 32
        },
        "CRB15000.Policy.Beta.sum": {
            "value": 0.0004951073410000003,
            "min": 0.0004951073410000003,
            "max": 0.001129096821,
            "count": 32
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1720527370",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\18125\\anaconda3\\envs\\mlagents\\Scripts\\mlagents-learn ./config/HighBatch.yaml --run-id newhold --env=./Builds/newHold/ABB-RL --num-envs=8 --resume",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.3.0+cpu",
        "numpy_version": "1.22.4",
        "end_time_seconds": "1720557054"
    },
    "total": 29683.610045399982,
    "count": 1,
    "self": 4.740985299926251,
    "children": {
        "run_training.setup": {
            "total": 0.36887010000646114,
            "count": 1,
            "self": 0.36887010000646114
        },
        "TrainerController.start_learning": {
            "total": 29678.50019000005,
            "count": 1,
            "self": 15.82227369362954,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.76280340005178,
                    "count": 1,
                    "self": 7.76280340005178
                },
                "TrainerController.advance": {
                    "total": 29654.868882106384,
                    "count": 1392846,
                    "self": 14.464685456361622,
                    "children": {
                        "env_step": {
                            "total": 29102.659769908874,
                            "count": 1392846,
                            "self": 28115.02953170007,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 976.5500320293941,
                                    "count": 1398223,
                                    "self": 48.07492839649785,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 928.4751036328962,
                                            "count": 1374016,
                                            "self": 928.4751036328962
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 11.080206179409288,
                                    "count": 1392845,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 237345.12232910306,
                                            "count": 1398215,
                                            "is_parallel": true,
                                            "self": 5380.165219452698,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0013245998416095972,
                                                    "count": 8,
                                                    "is_parallel": true,
                                                    "self": 0.0005406998097896576,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0007839000318199396,
                                                            "count": 16,
                                                            "is_parallel": true,
                                                            "self": 0.0007839000318199396
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 231964.95578505052,
                                                    "count": 1398215,
                                                    "is_parallel": true,
                                                    "self": 70.09232499345671,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 49.96472535585053,
                                                            "count": 1398215,
                                                            "is_parallel": true,
                                                            "self": 49.96472535585053
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 231690.94549202872,
                                                            "count": 1398215,
                                                            "is_parallel": true,
                                                            "self": 231690.94549202872
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 153.9532426724909,
                                                            "count": 1398215,
                                                            "is_parallel": true,
                                                            "self": 66.12985924701206,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 87.82338342547882,
                                                                    "count": 2796430,
                                                                    "is_parallel": true,
                                                                    "self": 87.82338342547882
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 537.7444267411483,
                            "count": 1392845,
                            "self": 19.488688518991694,
                            "children": {
                                "process_trajectory": {
                                    "total": 77.59165712224785,
                                    "count": 1392845,
                                    "self": 77.23795172187965,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.35370540036819875,
                                            "count": 13,
                                            "self": 0.35370540036819875
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 440.6640810999088,
                                    "count": 33,
                                    "self": 282.4627870983677,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 158.2012940015411,
                                            "count": 2640,
                                            "self": 158.2012940015411
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.00000761449337e-06,
                    "count": 1,
                    "self": 1.00000761449337e-06
                },
                "TrainerController._save_models": {
                    "total": 0.046229799976572394,
                    "count": 1,
                    "self": 0.015818500076420605,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.03041129990015179,
                            "count": 1,
                            "self": 0.03041129990015179
                        }
                    }
                }
            }
        }
    }
}